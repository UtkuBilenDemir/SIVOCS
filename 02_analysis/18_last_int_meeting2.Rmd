---
title: "18_last_int_meeting2"
output: 
  html_document:
    df_print: paged
    self_contained: false
---

```{r setup, include=FALSE}
source("./02_analysis/02_static_responses.R")
source("./02_analysis/99_question_groups.R")
# Load the feature importances from python script
feature_list <- read.csv("./02_analysis/PFA_feature_importance.csv")

```

```{r include = FALSE}
library(psych)
library(plotly)
library(lavaan)
```


## Principal Feature Analysis

> In some applications it might be desired to pick a subset of the original features rather then find a mapping that uses all of the original features. The benefits of finding this subset of features could be in saving cost of computing unnecessary features, saving cost of sensors (in physical measurement systems), and in excluding noisy features while keeping their information using “clean” features (for example tracking points on a face using easy to track points- and inferring the other points based on those few measurements).


How does the algorithm look like:

```python:

class PFA(object):
    def __init__(self, n_features, q=None):
        self.q = q
        self.n_features = n_features

    def fit(self, X):
        if not self.q:
            self.q = X.shape[1]

        sc = StandardScaler()
        X = sc.fit_transform(X)

        pca = PCA(n_components=self.q).fit(X)
        A_q = pca.components_.T

        kmeans = KMeans(n_clusters=self.n_features).fit(A_q)
        clusters = kmeans.predict(A_q)
        cluster_centers = kmeans.cluster_centers_

        dists = defaultdict(list)
        for i, c in enumerate(clusters):
            dist = euclidean_distances([A_q[i, :]], [cluster_centers[c, :]])[0][0]
            dists[c].append((i, dist))

        self.indices_ = [sorted(f, key=lambda x: x[1])[0][0] for f in dists.values()]
        self.features_ = X[:, self.indices_]
```

##  Results of PFA

* PFA has been looped **1000** times, feature frequencies are as follows


```{r fig.height=20}

fig <- plot_ly(x = feature_list$X1, 
               y = feature_list$X0, 
               type = 'bar', 
               orientation = 'h'
               ) %>% 
  layout(yaxis = list(categoryorder = "total ascending"))

fig
```


* Following features have been removed (some following the PFA and some after qualitative analysis):


```{r pressure, echo=FALSE}
features_to_rm <- tail(feature_list$X0, 40)
# Qualitatively select the worse performing features
features_to_rm <- features_to_rm[c(22,26,29:40)]
features_to_rm <- c(features_to_rm, 
                    "dissChannels.trad.",
                    "dissChannels.socmed.",
                    "dissChannels.consult.",
                    "dissChannels.events.", 
                    "dissChannels.public.",
                    "concepts.data.",
                    "concepts.code.",
                    "concepts.infra.",
                    "contribToSI.rate.",
                    "groupsInvolved.res.",
                    "natureOfInvolvement.res.",
                    "contribToSI.rate."
                    )

# remove the weak features
df_red <- feat_df.num_o[, !(colnames(feat_df.num_o ) %in% features_to_rm)]

features_to_rm
```

## Factor Analysis

* Determine Number of Factors to Extract

```{r echo = FALSE}
library(nFactors)
ev <- eigen(cor(df_red)) # get eigenvalues

ap <- parallel(subject=nrow(df_red),var=ncol(df_red),
               rep=100,cent=.05)
nS <- nScree(x=ev$values, aparallel=ap$eigen$qevpea)
plotnScree(nS)  # 9 Factors

```

```{r echo = FALSE}
# PCA Variable Factor Map 
library(FactoMineR)
result <- PCA(df_red) # graphs generated automatically

```

* Explanatory Factor Analysis

```{r}
# --- FA explanatory
# Maximum Likelihood Factor Analysis
# entering raw data and extracting 3 factors, 
# with varimax rotation 
fit <- factanal(df_red, 8, rotation="varimax")
print(fit, digits=2, cutoff=.3, sort=TRUE)
# plot factor 1 by factor 2 
#load <- fit$loadings[,1:2] 
#plot(load,type="n") # set up plot 
#text(load,labels=names(df_red),cex=.7) # add variable names


#fit$loadings

```


## 2 Confirmatory Factor Analysis Model

### 1. Theory driven model

```{r}
model_theory <-"
  ## SI Familiarity
  fam =~ familiarWithSI.response.+transdisciplinaryExp.rate.
  
  ## intention_agency
  ia_human_condition =~ motivation.welfare.+benefitForNonAcademy+impulseForNonAcad.soc.+targetGroupsGoals.improve.+impulseForNonAcad.health.+impulseForNonAcad.ecol.
  
  ia_non_academic =~ impulseForNonAcad.econ.+impulseForNonAcad.tech.
  
  ## transdisciplinary_apects
  transdisciplinary_social =~ groupsInvolved.citiz.+groupsInvolved.civsoc.+groupsInvolved.welfare.+natureOfInvolvement.citiz.+natureOfInvolvement.civsoc.+natureOfInvolvement.welfare.+targetGroupsGoals.socneeds.+targetGroupsGoals.socgroups.+targetGroupsGoals.empower.+targetGroupsGoals.diversity.
  
  ## outcome
  outcome_public =~ impactTargetGroup.pub.+impactTargetGroup.socgr.+impactTargetGroup.welfare.+impactTargetGroup.civsoc.+kindOfChange.pub.+kindOfChange.socgr.+kindOfChange.welfare.+kindOfChange.civsoc.
  
  outcome_statement =~ Impactstatements.capab.+Impactstatements.emanc.+Impactstatements.understanding.+Impactstatements.mitig.+Impactstatements.unknown.+Impactstatements.unaddressed.
  
  ## MISC:scalability
  scale =~ scalabilityRating.up.+scalabilityRating.out.+scalabilityRating.deep.
  
  ## MISC:policy
  policy =~ groupsInvolved.policy.+impactTargetGroup.policy.+kindOfChange.policy.+natureOfInvolvement.policy.+groupsInvolved.policy.+adoptByPolicyHow.SQ001. 
  
  ## MISC:business
  busi =~ groupsInvolved.busi.+impactTargetGroup.busi.+kindOfChange.busi.
"

```

```{r}
library(tidyverse)
library(paletteer)
library(gt)

pizzaplace %>%
  mutate(type = case_when(
    type == "chicken" ~ "chicken (pizzas with chicken as a major ingredient)",
    type == "classic" ~ "classic (classical pizzas)",
    type == "supreme" ~ "supreme (pizzas that try a little harder)",
    type == "veggie" ~ "veggie (pizzas without any meats whatsoever)",
  )) %>%
  mutate(size = factor(size, levels = c("S", "M", "L", "XL", "XXL"))) %>%
  dplyr::group_by(type, size) %>%
  dplyr::summarize(
    sold = n(),
    income = sum(price)
  ) %>%
  gt(rowname_col = "size") %>%
  tab_header(title = md("&#127829; Pizzas Sold in 2015 &#127829;")) %>%
  fmt_number(
    columns = vars(sold),
    decimals = 0,
    use_seps = TRUE
  ) %>%
  fmt_currency(
    columns = vars(income),
    currency = "USD"
  ) %>%
  cols_align(align = "right", columns = TRUE) %>%
  data_color(
    columns = vars(sold, income),
    colors = scales::col_numeric(
      palette = paletteer::paletteer_d(
        palette = "ggsci::red_material"
      ) %>% as.character(),
      domain = NULL
    ),
    alpha = 0.8
  ) %>%
  summary_rows(
    groups = TRUE,
    columns = vars(sold),
    fns = list(TOTAL = "sum"),
    formatter = fmt_number,
    decimals = 0,
    use_seps = TRUE
  ) %>%
  summary_rows(
    groups = TRUE,
    columns = vars(income),
    fns = list(TOTAL = "sum"),
    formatter = fmt_currency,
    currency = "USD"
  ) %>%
  grand_summary_rows(
    columns = vars(sold),
    fns = list(`GRAND TOTAL` = "sum"),
    formatter = fmt_number,
    decimals = 0,
    use_seps = TRUE
  ) %>%
  grand_summary_rows(
    columns = vars(income),
    fns = list(`GRAND TOTAL` = "sum"),
    formatter = fmt_currency,
    currency = "USD"
  ) %>%
  tab_footnote(
    footnote = "The pizza category with the highest total sales.",
    locations = cells_row_groups("classic (classical pizzas)")
  ) %>%
  tab_footnote(
    footnote = md("Custom sizes for **The Greek** pizza."),
    locations = cells_stub(c("XL", "XXL"))
  ) %>%
  tab_footnote(
    footnote = md("This is a new record. Truly, 2015 was a **great** year for the `pizzaplace`."),
    locations = cells_grand_summary(columns = vars(sold))
  ) %>%
  tab_options(
    summary_row.background.color = "#ACEACE80",
    grand_summary_row.background.color = "#990000",
    row_group.background.color = "#FFEFDB80",
    heading.background.color = "#EFFBFC",
    column_labels.background.color = "#EFFBFC",
    stub.background.color = "#EFFBFC",
    table.font.color = "#323232",
    table_body.hlines.color = "#989898",
    table_body.border.top.color = "#989898",
    heading.border.bottom.color = "#989898",
    row_group.border.top.color = "#989898",
    row_group.border.bottom.style = "none",
    stub.border.style = "dashed",
    stub.border.color = "#989898",
    stub.border.width = "1px",
    summary_row.border.color = "#989898",
    table.width = "60%"
  ) %>%
  opt_all_caps()
   


```



### 2 EFA driven model

```{r}
model_efa <- "
  f1 =~ impulseForNonAcad.soc.+groupsInvolved.citiz.+targetGroupsGoals.socneeds.+targetGroupsGoals.socgroups.+impactTargetGroup.socgr.+Impactstatements.capab.+Impactstatements.emanc.+Impactstatements.understanding.+Impactstatements.mitig.+transdisciplinaryExp.rate.+familiarWithSI.response. 
  f2 =~ motivation.welfare.+benefitForNonAcademy+targetGroupsGoals.improve.+impulseForNonAcad.health.+impactTargetGroup.pub. 
  f3 =~ groupsInvolved.policy.+impactTargetGroup.policy.+kindOfChange.policy.+natureOfInvolvement.policy.+impulseForNonAcad.econ.+natureOfInvolvement.policy.
  f4 =~ groupsInvolved.welfare.+natureOfInvolvement.welfare.+impactTargetGroup.welfare.+kindOfChange.welfare. 
  f5 =~ groupsInvolved.civsoc.+natureOfInvolvement.civsoc.+impactTargetGroup.civsoc.+kindOfChange.civsoc.
  f6 =~ impactTargetGroup.busi.+kindOfChange.busi.+groupsInvolved.busi.
  f7 =~ scalabilityRating.up.+scalabilityRating.out.+scalabilityRating.deep.
  f8 =~ kindOfChange.pub.+kindOfChange.socgr.+kindOfChange.acad.
"

```

```{r echo = FALSE}
fit_theory <- cfa(model_theory, df_red)
fit_efa <- cfa(model_efa, df_red)

```


### Optimization opportunities?

```{r message=FALSE, warning=FALSE}
modificationindices(fit_theory) %>% arrange(-mi) %>% head(10)
```

```{r message=FALSE, warning=FALSE}
modificationindices(fit_efa) %>% arrange(-mi) %>% head(10)
```


### Which model is better?

```{r}
anova(fit_theory, fit_efa)
```


### The comparison between Models and *(self assesment) SI rate*

```{r}

DF.refined <- data.frame(predict(fit_theory))


a <- scales::rescale(apply(DF.refined, mean, MARGIN = 1), to = c(0, 10))
b <- feat_df.num_o$contribToSI.rate.
c <- 1:length(a)

ab <- as.data.frame(cbind(a,b,c))
library(ggplot2)
ggplot(ab, aes(x = c)) + 
  geom_line(aes(y = a), color = "darkred") + 
  geom_line(aes(y = b), color="steelblue") 



DF.refined2 <- data.frame(predict(fit_efa))

d <- scales::rescale(apply(DF.refined2, mean, MARGIN = 1), to = c(0, 10))

db <- as.data.frame(cbind(d,b,c))
ggplot(db, aes(x = c)) + 
  geom_line(aes(y = d), color = "darkred") + 
  geom_line(aes(y = b), color="steelblue") 

var_prop_efa <- c(0.13,  0.06,    0.05,    0.05,    0.05,    0.05,    0.04,    0.03)
new_DF_refined2 <- as.data.frame( as.matrix(DF.refined2) %*% diag(var_prop_efa))

f <- scales::rescale(apply(new_DF_refined2, mean, MARGIN = 1), to = c(0, 10))

```

```{r}
data <- data.frame(a,b,c,d,f)
fig <- plot_ly(data, x = ~c, y = ~a, name = 'theory', type = 'bar') 
fig <- fig %>% add_trace(y = ~b, name = 'contribToSI.rate', type = 'bar') 
fig <- fig %>% add_trace(y = ~d, name = 'efa', type = 'bar')
fig <- fig %>% add_trace(y = ~f, name = 'efa_scaled', type = 'bar')

fig

```
  
* Neue Varible: log(pfa)
```{r fig.height=10}
feature_list_red <- feature_list[!(feature_list$X0 %in% features_to_rm),]
feature_list_red$logX <-  log(feature_list_red$X1)
df_red2 <- df_red
for (i in seq_along(feature_list_red$logX)) {
  df_red2[, i] <- df_red2[, i] * feature_list_red$logX[i]
}

g <- scales::rescale(apply(df_red2, mean, MARGIN = 1), to = c(0, 10))
data$g <- g


library(plotly) 
fig1 <- plot_ly(x = data$c, y = data$a, type = 'scatter', mode = 'lines', name="theory") 
fig2 <- plot_ly(x = data$c, y = data$b, type = 'scatter', mode = 'lines', name="contribToSI") 
fig3 <- plot_ly(x = data$c, y = data$d, type = 'scatter', mode = 'lines', name="efa") 
fig4 <- plot_ly(x = data$c, y = data$f, type = 'scatter', mode = 'lines', name="efa_scaled") 
fig5 <- plot_ly(x = data$c, y = data$g, type = 'scatter', mode = 'lines', name="log(pfa)") 
fig <- subplot(fig1, fig2, fig3, fig4, fig5, nrows = 5) %>% 
  layout(title = list(text = ""),
         plot_bgcolor='#e5ecf6', 
         xaxis = list( 
           zerolinecolor = '#ffff', 
           zerolinewidth = 2, 
           gridcolor = 'ffff'), 
         yaxis = list( 
           zerolinecolor = '#ffff', 
           zerolinewidth = 2, 
           gridcolor = 'ffff')) 
fig

```

```{r}
mean(aggregate( a ~ b , data = data , sum , na.rm = TRUE )$a)
mean(aggregate( d ~ b , data = data , sum , na.rm = TRUE )$d)
mean(aggregate( f ~ b , data = data , sum , na.rm = TRUE )$f)
mean(aggregate( g ~ b , data = data , sum , na.rm = TRUE )$g)

```




```{r}
mean(a-b)
mean(d-b)
mean(f-b)
mean(g-b)
```



```{r}
cor(g,b, use = "pairwise.complete.obs", method = "spearman")
```

```{r}
si_self  <- likert_recode(feat_df.num$contribToSI.rate.)

si_df <- as.data.frame(cbind(SI.self_assessment = si_self,
                             SI.theory_driven = a,
                             SI.efa_driven = d,
                             SI.efa_scaled = f,
                             SI.log_efa = g
                             ))
```


```{r SI-Models, echo=FALSE, fig.width=32, fig.height=8, dev='svg', fig.retina=2, fig.align='center'}
library(patchwork)
# library(DEGreport)
library(dplyr)
library(plyr)
library(tidyverse)

si_df$SI.self_assessment <- likert_recode(feat_df.num$contribToSI.rate.)

acor <- cor(si_df$SI.theory_driven, feat_df$contribToSI.rate., use = "pairwise.complete.obs", method = "spearman")
dcor <- cor(si_df$SI.efa_driven, feat_df$contribToSI.rate., use = "pairwise.complete.obs", method = "spearman")
fcor <- cor(si_df$SI.efa_scaled, feat_df$contribToSI.rate., use = "pairwise.complete.obs", method = "spearman")
gcor <- cor(si_df$SI.log_efa, feat_df$contribToSI.rate., use = "pairwise.complete.obs", method = "spearman")


a <- si_df[, c(1,2)] %>% 
  filter(!is.na(SI.self_assessment)) %>%
  gather(key="SI.theory_driven", value="SI.self_assessment") %>%
  ggplot(aes(x=SI.theory_driven, y=SI.self_assessment, fill=SI.self_assessment),  show.legend = FALSE) +
    geom_boxplot() +
  ylab(" ") +
  theme_light() +
  theme(axis.text.y=element_blank()) +
  scale_fill_discrete(name = "SI Rate (self-assessment)") + 
  xlab("Theory driven SI-Index") + 
  scale_fill_manual(values=c("#FC4E07", "#E7B800", "#00AFBB"), name="SI Rate (self-assessment)") + 
  geom_text( aes( x=0, y=3, label=paste0("Cor: " , round(acor, 2))),                 , 
           color="black", 
           size=4, fontface="bold" )


b <- si_df[, c(1,3)] %>% 
  filter(!is.na(SI.self_assessment)) %>%
  gather(key="SI.efa_driven", value="SI.self_assessment") %>%
  ggplot(aes(x=SI.efa_driven, y=SI.self_assessment, fill=SI.self_assessment),  show.legend = FALSE) +
    geom_boxplot() +
  ylab(" ") +
  theme_light() +
  theme(axis.text.y=element_blank()) +
  scale_fill_discrete(name = "SI Rate (self-assessment)") + 
  xlab("EFA driven SI-Index") + 
  scale_fill_manual(values=c("#FC4E07", "#E7B800", "#00AFBB"), name="SI Rate (self-assessment)") +
  # geom_cor(method = "kendall", ypos = 1e5)+ 
  geom_text( aes( x=0, y=3, label=paste0("Cor: " , round(dcor, 2))),                 , 
           color="black", 
           size=4, fontface="bold" )



c <- si_df[, c(1,4)] %>% 
  filter(!is.na(SI.self_assessment)) %>%
  gather(key="SI.efa_scaled", value="SI.self_assessment") %>%
  ggplot(aes(x=SI.efa_scaled, y=SI.self_assessment, fill=SI.self_assessment),  show.legend = FALSE) +
    geom_boxplot() +
  ylab(" ") +
  theme_light() +
  theme(axis.text.y=element_blank()) +
  scale_fill_discrete(name = "SI Rate (self-assessment)") + 
  xlab("EFA driven and scaled SI-Index") + 
  scale_fill_manual(values=c("#FC4E07", "#E7B800", "#00AFBB"), name="SI Rate (self-assessment)")+ 
  geom_text( aes( x=0, y=3, label=paste0("Cor: " , round(fcor, 2))),                 , 
           color="black", 
           size=4, fontface="bold" )


d <- si_df[, c(1,5)] %>% 
  filter(!is.na(SI.self_assessment)) %>%
  gather(key="SI.log_efa", value="SI.self_assessment") %>%
  ggplot(aes(x=SI.log_efa, y=SI.self_assessment, fill=SI.self_assessment),  show.legend = FALSE) +
    geom_boxplot() +
  ylab(" ") +
  theme_light() +
  theme(axis.text.y=element_blank()) +
  scale_fill_discrete(name = "SI Rate (self-assessment)") + 
  xlab("Solely PFA based log. scaled SI-Index") + 
  scale_fill_manual(values=c("#FC4E07", "#E7B800", "#00AFBB"), name="SI Rate (self-assessment)")+ 
  geom_text( aes( x=0, y=3, label=paste0("Cor: " , round(gcor, 2))),                 , 
           color="black", 
           size=4, fontface="bold" )


a + b + c + d

```


```{r, echo=FALSE, fig.width=10, fig.height=4, dev='svg', fig.retina=2, fig.align='center'}
col_seq <- c("#f4a582",
"#92c5de",
"#2166ac")

a <- si_df[, c(1,2)] %>% 
  filter(!is.na(SI.self_assessment)) %>%
  gather(key="SI.theory_driven", value="SI.self_assessment") %>%
  ggplot(aes(x=SI.theory_driven, y=SI.self_assessment, fill=SI.self_assessment),  show.legend = FALSE) +
    geom_boxplot() +
  ylab(" ") +
  theme_light() +
  theme(axis.text.y=element_blank()) +
  scale_fill_discrete(name = "SI Rate (self-assessment)") + 
  xlab("Theory driven SI-Index") + 
  scale_fill_manual(values=col_seq, name="SI Rate (self-assessment)") + 
guides(fill=guide_legend(reverse = TRUE))

a

```

```{r}
den_df <- as.data.frame(cbind( a = si_df$SI.theory_driven, b = feat_df.num$contribToSI.rate.))
den_df

# Change the confidence interval fill color
ggplot(den_df, aes(x=a, y=b)) + 
  geom_point(shape=18, color="blue")+
  geom_smooth(method=lm,  linetype="dashed",
             color="darkred", fill="blue")
```

